{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML1403(Assignment_MidTerm)_AnanyaSinghipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InEkzxtObGba"
      },
      "source": [
        "**The CIFAR-100 dataset** (Canadian Institute for Advanced Research, 100 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. There are 600 images per class. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs). There are 500 training images and 100 testing images per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdsVTxCTXI_9"
      },
      "source": [
        "We need to import these dependencies. You can do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu8ZN8sg7nn5"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtpzGbeLXP3h"
      },
      "source": [
        "Model configuration\n",
        "Now, let’s set some configuration options for our model:\n",
        "\n",
        "**The batch size** is the amount of samples that will be fed forward in your model at once, after which the loss value is computed. You could either feed the model the entire training batch, one sample every time or a minibatch – and you can set this value by specifying batch_size.\n",
        "\n",
        "**The image width, image height and number of channels **. Width and height are 32, respectively, and number of channels is 3, as the dataset contains RGB images.\n",
        "\n",
        "The **loss function** used to compare predictions with ground truth during training. We use sparse categorical crossentropy loss. We skip the “why” for now – I’ll show you later why we use sparse instead of regular categorical crossentropy loss.\n",
        "\n",
        "The **number of classes** and **number of epochs** (or iterations), which we set to 10 and 100, respectively. We set the first to 10 because we have ten distinct classes – the digits 0 to 9. The second is set to 100 because I’m assuming that we’ll have passed maximum model performance by then. We don’t want to be training infinitely, as this induces overfitting.\n",
        "\n",
        "The** optimizer**, or the method by which we update the weights of our neural network. We use Adam optimization – which is a relatively state-of-the-art optimizer and common in today’s neural networks.\n",
        "\n",
        "20% of our training data will be used for validation purposes; that is, used to test the model with non-training-data during training.\n",
        "\n",
        "**Verbosity mod**e is set to “1”, which means “True”, which means that all the output is displayed on screen. This is good for understanding what happens during training, but it’s best to turn it off when you actually train models, as it slows down the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7SXuym8Bxw"
      },
      "source": [
        "# Configuration of our machine learning model\n",
        "batch_size = 2048\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 90\n",
        "optimizer = Adam()\n",
        "validation_split = 0.25\n",
        "verbosity = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwwgI85yXtCn"
      },
      "source": [
        "**Loading & preparing CIFAR-10 data**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Now, let’s load some CIFAR-100 data. We can do so easily because Keras provides intuitive access to the dataset by design:\n",
        "\n",
        "cifar100. load_data() Loads the CIFAR100 dataset. This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 100 fine-grained classes that are grouped into 20 coarse-grained classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up9z5ZWx8Bz2"
      },
      "source": [
        "# Loading of CIFAR100 data set\n",
        "(input_train_data, target_train_data), (input_test_data, target_test_data) = cifar100.load_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOJYdGmXzI8"
      },
      "source": [
        "The next step is to **determine the shape of one sample**.\n",
        "\n",
        " This is required by Keras to understand what data it can expect in the input layer of your neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG60zSTD8QvO"
      },
      "source": [
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zmvsmVbX-zz"
      },
      "source": [
        "Firstly, we’ll convert our data into float32 format, which presumably speeds up training. Then, we normalize the data, into the [−1,1] range.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leo4Dax78UQ2"
      },
      "source": [
        "# Parse numbers as floats\n",
        "input_train = input_train_data.astype('float32')\n",
        "input_test = input_test_data.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iN6D775YHGW"
      },
      "source": [
        "As the distribution of the feature values in the images can be very different from each other, the images are normalized by dividing each image by 255 as the range of each individual color is [0,255]. Thus, the rescaled images have all features in the new range [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtlellfD8jP0"
      },
      "source": [
        "# Normalize data\n",
        "input_train = input_train_data / 255\n",
        "input_test = input_test_data / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBpW5JXuYhRQ"
      },
      "source": [
        "We can then create the architecture of our model.\n",
        "\n",
        "**Sequential imodel** we have chosen to build for this model. It allows you to build a model layer by layer. Each layer has weights that correspond to the layer the follows it. We use the 'add()' function to add layers to our model.\n",
        "\n",
        "Next, it’s time to stack a few layers. \n",
        "\n",
        "Firstly, we’ll use three convolutional blocks – which is the nickname I often use for convolutional layers with some related ones. \n",
        "\n",
        "In this case, the related layer that is applied every time is a MaxPooling2D one directly after the Conv2D layer. As you can see, each time, the numer of feature maps increases – from 32, to 64, to 128. This is done because the model then learns a limited number of “generic” patterns (32) and a high amount of patterns unique to the image (128). Max Pooling ensures translation invariance, as we discussed before.\n",
        "\n",
        "After the convolutional blocks, we add a Flatten layer. The Dense layers, which are responsible for generating the actual classifications, only work with one-dimensional data. Flatten makes this happen: it converts the multidimensional feature maps into one-dimensional shape. Great!\n",
        "\n",
        "The Dense layers ensure that classification is possible. As you can see, in terms of the number of outputs per layer, we create an information bottleneck that eventually converges in no_classes – thus 10 – outputs, exactly the number of unique classes in our dataset. As we’re using the Softmax activation function, we’ll get a discrete multiclass probability distribution as our output for any input. From this distribution, we can draw the one with the highest value, which is the most likely class for our input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX0yldsD83ZX"
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80XpVlgYz2U"
      },
      "source": [
        "As above we had created skeleton for our model. We don’t have a model yet, as it must be compiled first. This can be done by calling model.compile. It involves specifying settings for the training process, such as the loss function and the optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkKbF2lc87Id"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YaOAfCTZE__"
      },
      "source": [
        "Once the model is compiled, we do have a model, but it’s not yet trained. We can start the training process by calling model.fit, which fits our data (in this case our training data and the corresponding targets) and specifies some settings for our training process, ones that we configured before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zrJBAw9Agj",
        "outputId": "b7f360a8-070a-4377-c992-61ac677c8094"
      },
      "source": [
        "# Fit data to model\n",
        "\n",
        "\n",
        "history_fit_data = model.fit(input_train_data, target_train_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_split=validation_split,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "19/19 [==============================] - 2s 70ms/step - loss: 6.1430 - accuracy: 0.0166 - val_loss: 4.5466 - val_accuracy: 0.0215\n",
            "Epoch 2/90\n",
            "19/19 [==============================] - 1s 55ms/step - loss: 4.4690 - accuracy: 0.0369 - val_loss: 4.3902 - val_accuracy: 0.0455\n",
            "Epoch 3/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 4.2703 - accuracy: 0.0612 - val_loss: 4.1837 - val_accuracy: 0.0765\n",
            "Epoch 4/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 4.0415 - accuracy: 0.0980 - val_loss: 4.0029 - val_accuracy: 0.1010\n",
            "Epoch 5/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.8212 - accuracy: 0.1302 - val_loss: 3.8039 - val_accuracy: 0.1288\n",
            "Epoch 6/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.6465 - accuracy: 0.1549 - val_loss: 3.6711 - val_accuracy: 0.1454\n",
            "Epoch 7/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.5011 - accuracy: 0.1763 - val_loss: 3.5528 - val_accuracy: 0.1714\n",
            "Epoch 8/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.3698 - accuracy: 0.2006 - val_loss: 3.4705 - val_accuracy: 0.1841\n",
            "Epoch 9/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.2568 - accuracy: 0.2190 - val_loss: 3.4152 - val_accuracy: 0.1926\n",
            "Epoch 10/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 3.1485 - accuracy: 0.2379 - val_loss: 3.3707 - val_accuracy: 0.2046\n",
            "Epoch 11/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 3.0720 - accuracy: 0.2543 - val_loss: 3.3158 - val_accuracy: 0.2194\n",
            "Epoch 12/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.9721 - accuracy: 0.2727 - val_loss: 3.2857 - val_accuracy: 0.2178\n",
            "Epoch 13/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.8873 - accuracy: 0.2897 - val_loss: 3.1802 - val_accuracy: 0.2398\n",
            "Epoch 14/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 2.7892 - accuracy: 0.3101 - val_loss: 3.1529 - val_accuracy: 0.2439\n",
            "Epoch 15/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.7160 - accuracy: 0.3258 - val_loss: 3.1248 - val_accuracy: 0.2530\n",
            "Epoch 16/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 2.6382 - accuracy: 0.3417 - val_loss: 3.0591 - val_accuracy: 0.2626\n",
            "Epoch 17/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.5779 - accuracy: 0.3534 - val_loss: 3.0786 - val_accuracy: 0.2655\n",
            "Epoch 18/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.4788 - accuracy: 0.3740 - val_loss: 3.0849 - val_accuracy: 0.2610\n",
            "Epoch 19/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.4416 - accuracy: 0.3802 - val_loss: 3.0494 - val_accuracy: 0.2690\n",
            "Epoch 20/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 2.3799 - accuracy: 0.3960 - val_loss: 3.0538 - val_accuracy: 0.2783\n",
            "Epoch 21/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 2.2957 - accuracy: 0.4124 - val_loss: 3.0224 - val_accuracy: 0.2821\n",
            "Epoch 22/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 2.2255 - accuracy: 0.4298 - val_loss: 3.0209 - val_accuracy: 0.2835\n",
            "Epoch 23/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 2.1583 - accuracy: 0.4424 - val_loss: 3.0871 - val_accuracy: 0.2806\n",
            "Epoch 24/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 2.1436 - accuracy: 0.4454 - val_loss: 3.0959 - val_accuracy: 0.2831\n",
            "Epoch 25/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 2.0871 - accuracy: 0.4608 - val_loss: 3.1030 - val_accuracy: 0.2842\n",
            "Epoch 26/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 2.0223 - accuracy: 0.4734 - val_loss: 3.0684 - val_accuracy: 0.2898\n",
            "Epoch 27/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.9414 - accuracy: 0.4926 - val_loss: 3.1096 - val_accuracy: 0.2853\n",
            "Epoch 28/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.8998 - accuracy: 0.5031 - val_loss: 3.0849 - val_accuracy: 0.2912\n",
            "Epoch 29/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.8610 - accuracy: 0.5129 - val_loss: 3.1200 - val_accuracy: 0.2906\n",
            "Epoch 30/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.7999 - accuracy: 0.5262 - val_loss: 3.1770 - val_accuracy: 0.2912\n",
            "Epoch 31/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.7436 - accuracy: 0.5410 - val_loss: 3.2207 - val_accuracy: 0.2938\n",
            "Epoch 32/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.7193 - accuracy: 0.5475 - val_loss: 3.2533 - val_accuracy: 0.2930\n",
            "Epoch 33/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.6518 - accuracy: 0.5639 - val_loss: 3.2340 - val_accuracy: 0.2998\n",
            "Epoch 34/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.5829 - accuracy: 0.5828 - val_loss: 3.2963 - val_accuracy: 0.2914\n",
            "Epoch 35/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.5712 - accuracy: 0.5828 - val_loss: 3.3387 - val_accuracy: 0.2942\n",
            "Epoch 36/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 1.5122 - accuracy: 0.5973 - val_loss: 3.3541 - val_accuracy: 0.2945\n",
            "Epoch 37/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.4708 - accuracy: 0.6087 - val_loss: 3.3699 - val_accuracy: 0.2974\n",
            "Epoch 38/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.4222 - accuracy: 0.6198 - val_loss: 3.4160 - val_accuracy: 0.2957\n",
            "Epoch 39/90\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 1.3768 - accuracy: 0.6318 - val_loss: 3.5408 - val_accuracy: 0.2882\n",
            "Epoch 40/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.3614 - accuracy: 0.6332 - val_loss: 3.5045 - val_accuracy: 0.2928\n",
            "Epoch 41/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.3329 - accuracy: 0.6398 - val_loss: 3.5862 - val_accuracy: 0.2869\n",
            "Epoch 42/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.2418 - accuracy: 0.6683 - val_loss: 3.6543 - val_accuracy: 0.2900\n",
            "Epoch 43/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 1.2085 - accuracy: 0.6746 - val_loss: 3.7334 - val_accuracy: 0.2917\n",
            "Epoch 44/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.1670 - accuracy: 0.6860 - val_loss: 3.7283 - val_accuracy: 0.2917\n",
            "Epoch 45/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 1.1234 - accuracy: 0.6986 - val_loss: 3.8706 - val_accuracy: 0.2815\n",
            "Epoch 46/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 1.0999 - accuracy: 0.7030 - val_loss: 3.8820 - val_accuracy: 0.2873\n",
            "Epoch 47/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.0725 - accuracy: 0.7091 - val_loss: 3.9859 - val_accuracy: 0.2814\n",
            "Epoch 48/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 1.0239 - accuracy: 0.7223 - val_loss: 3.9761 - val_accuracy: 0.2868\n",
            "Epoch 49/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.9907 - accuracy: 0.7319 - val_loss: 4.1559 - val_accuracy: 0.2811\n",
            "Epoch 50/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.9659 - accuracy: 0.7363 - val_loss: 4.1235 - val_accuracy: 0.2831\n",
            "Epoch 51/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.9072 - accuracy: 0.7560 - val_loss: 4.2405 - val_accuracy: 0.2818\n",
            "Epoch 52/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.8851 - accuracy: 0.7620 - val_loss: 4.3082 - val_accuracy: 0.2762\n",
            "Epoch 53/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.8461 - accuracy: 0.7723 - val_loss: 4.3897 - val_accuracy: 0.2798\n",
            "Epoch 54/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.8178 - accuracy: 0.7798 - val_loss: 4.4409 - val_accuracy: 0.2777\n",
            "Epoch 55/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.7761 - accuracy: 0.7944 - val_loss: 4.5495 - val_accuracy: 0.2786\n",
            "Epoch 56/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.7394 - accuracy: 0.8056 - val_loss: 4.6069 - val_accuracy: 0.2799\n",
            "Epoch 57/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.7146 - accuracy: 0.8117 - val_loss: 4.6738 - val_accuracy: 0.2761\n",
            "Epoch 58/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.7581 - accuracy: 0.7922 - val_loss: 4.7404 - val_accuracy: 0.2730\n",
            "Epoch 59/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.7010 - accuracy: 0.8090 - val_loss: 4.8694 - val_accuracy: 0.2772\n",
            "Epoch 60/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.6566 - accuracy: 0.8240 - val_loss: 4.9356 - val_accuracy: 0.2741\n",
            "Epoch 61/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.6317 - accuracy: 0.8313 - val_loss: 5.0512 - val_accuracy: 0.2680\n",
            "Epoch 62/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.5775 - accuracy: 0.8514 - val_loss: 5.1489 - val_accuracy: 0.2686\n",
            "Epoch 63/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.5675 - accuracy: 0.8525 - val_loss: 5.2284 - val_accuracy: 0.2682\n",
            "Epoch 64/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.5577 - accuracy: 0.8517 - val_loss: 5.4131 - val_accuracy: 0.2678\n",
            "Epoch 65/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.5095 - accuracy: 0.8680 - val_loss: 5.4485 - val_accuracy: 0.2693\n",
            "Epoch 66/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.4985 - accuracy: 0.8695 - val_loss: 5.5414 - val_accuracy: 0.2688\n",
            "Epoch 67/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.4866 - accuracy: 0.8715 - val_loss: 5.6662 - val_accuracy: 0.2673\n",
            "Epoch 68/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.4509 - accuracy: 0.8836 - val_loss: 5.7414 - val_accuracy: 0.2685\n",
            "Epoch 69/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.4383 - accuracy: 0.8861 - val_loss: 5.8719 - val_accuracy: 0.2668\n",
            "Epoch 70/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.4312 - accuracy: 0.8882 - val_loss: 5.9978 - val_accuracy: 0.2627\n",
            "Epoch 71/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.4226 - accuracy: 0.8883 - val_loss: 5.9849 - val_accuracy: 0.2634\n",
            "Epoch 72/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.4050 - accuracy: 0.8930 - val_loss: 6.1011 - val_accuracy: 0.2712\n",
            "Epoch 73/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.3700 - accuracy: 0.9061 - val_loss: 6.2277 - val_accuracy: 0.2674\n",
            "Epoch 74/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.3293 - accuracy: 0.9201 - val_loss: 6.2844 - val_accuracy: 0.2690\n",
            "Epoch 75/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.3057 - accuracy: 0.9265 - val_loss: 6.4755 - val_accuracy: 0.2696\n",
            "Epoch 76/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2774 - accuracy: 0.9385 - val_loss: 6.5799 - val_accuracy: 0.2710\n",
            "Epoch 77/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2576 - accuracy: 0.9431 - val_loss: 6.7134 - val_accuracy: 0.2668\n",
            "Epoch 78/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2467 - accuracy: 0.9462 - val_loss: 6.8195 - val_accuracy: 0.2646\n",
            "Epoch 79/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2553 - accuracy: 0.9410 - val_loss: 6.9026 - val_accuracy: 0.2679\n",
            "Epoch 80/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2381 - accuracy: 0.9452 - val_loss: 7.0364 - val_accuracy: 0.2630\n",
            "Epoch 81/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.2219 - accuracy: 0.9500 - val_loss: 7.1798 - val_accuracy: 0.2642\n",
            "Epoch 82/90\n",
            "19/19 [==============================] - 1s 58ms/step - loss: 0.2313 - accuracy: 0.9456 - val_loss: 7.2550 - val_accuracy: 0.2617\n",
            "Epoch 83/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.2253 - accuracy: 0.9462 - val_loss: 7.3373 - val_accuracy: 0.2659\n",
            "Epoch 84/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.1965 - accuracy: 0.9566 - val_loss: 7.4583 - val_accuracy: 0.2638\n",
            "Epoch 85/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.1751 - accuracy: 0.9636 - val_loss: 7.7265 - val_accuracy: 0.2645\n",
            "Epoch 86/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.1717 - accuracy: 0.9640 - val_loss: 7.8020 - val_accuracy: 0.2669\n",
            "Epoch 87/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.1480 - accuracy: 0.9728 - val_loss: 7.8702 - val_accuracy: 0.2675\n",
            "Epoch 88/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.1313 - accuracy: 0.9779 - val_loss: 7.9395 - val_accuracy: 0.2618\n",
            "Epoch 89/90\n",
            "19/19 [==============================] - 1s 57ms/step - loss: 0.1303 - accuracy: 0.9771 - val_loss: 8.1709 - val_accuracy: 0.2656\n",
            "Epoch 90/90\n",
            "19/19 [==============================] - 1s 56ms/step - loss: 0.1135 - accuracy: 0.9810 - val_loss: 8.1965 - val_accuracy: 0.2682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4y7l9wiaw8s"
      },
      "source": [
        "Generating evaluation metrics\n",
        "\n",
        "Evaluation metrics are used to measure the quality of the statistical or machine learning model. Evaluating machine learning models or algorithms is essential for any project. There are many different types of evaluation metrics available to test a model.We have used accuracy model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh0Nv0uU9Aqw",
        "outputId": "b84a9c43-f968-4bf5-d307-f9adaf4e84af"
      },
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(input_test_data, target_test_data, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 7.920735836029053 / Test accuracy: 0.2808000147342682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDI8ene79Asx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}